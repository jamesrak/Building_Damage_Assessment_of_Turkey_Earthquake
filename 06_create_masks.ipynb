{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6cd1dd9a-9125-42fe-a679-378384265fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"MKL_NUM_THREADS\"] = \"1\" \n",
    "# os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\" \n",
    "# os.environ[\"OMP_NUM_THREADS\"] = \"1\" \n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "import random\n",
    "random.seed(1)\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import timeit\n",
    "from os import path, makedirs, listdir\n",
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "from multiprocessing import Pool\n",
    "from skimage.morphology import square, dilation, watershed, erosion\n",
    "from skimage import io\n",
    "\n",
    "from shapely.wkt import loads\n",
    "from shapely.geometry import mapping, Polygon, MultiPolygon\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "# def mask_for_polygon(poly, im_size=(1024, 1024)):\n",
    "#     img_mask = np.zeros(im_size, np.uint8)\n",
    "#     int_coords = lambda x: np.array(x).round().astype(np.int32)\n",
    "#     if(poly.geom_type=='MultiPolygon'):\n",
    "#         exteriors = [list(x.exterior.coords) for x in poly.geoms]\n",
    "#         interiors = []\n",
    "#         for p in poly.geoms:\n",
    "#             interiors.extend([int_coords(pi.coords) for pi in p.interiors if pi.coords is not None])\n",
    "        \n",
    "#     else:\n",
    "#         exteriors = [int_coords(poly.exterior.coords)]\n",
    "#         interiors = [int_coords(pi.coords) for pi in poly.interiors]\n",
    "    \n",
    "#     cv2.fillPoly(img_mask, exteriors, 1)\n",
    "#     cv2.fillPoly(img_mask, interiors, 0)\n",
    "#     return img_mask\n",
    "\n",
    "def mask_for_polygon(geom, im_size=(1024, 1024)):\n",
    "    img_mask = np.zeros(im_size, np.uint8)\n",
    "    int_coords = lambda x: np.array(x).round().astype(np.int32)\n",
    "\n",
    "    # If the geometry is a Polygon\n",
    "    if isinstance(geom, Polygon):\n",
    "        exteriors = [int_coords(geom.exterior.coords)]\n",
    "        interiors = [int_coords(pi.coords) for pi in geom.interiors]\n",
    "        cv2.fillPoly(img_mask, exteriors, 1)\n",
    "        cv2.fillPoly(img_mask, interiors, 0)\n",
    "\n",
    "    # If the geometry is a MultiPolygon\n",
    "    elif isinstance(geom, MultiPolygon):\n",
    "        for poly in geom.geoms:\n",
    "            exteriors = [int_coords(poly.exterior.coords)]\n",
    "            interiors = [int_coords(pi.coords) for pi in poly.interiors]\n",
    "            cv2.fillPoly(img_mask, exteriors, 1)\n",
    "            cv2.fillPoly(img_mask, interiors, 0)\n",
    "\n",
    "    # If the geometry is a Point\n",
    "    elif isinstance(geom, Point):\n",
    "        coords = int_coords(geom.coords[:1])  # Get the first coordinate tuple\n",
    "        try:\n",
    "            img_mask[coords[0][1], coords[0][0]] = 1  # y, x order\n",
    "        except:\n",
    "            None\n",
    "\n",
    "    return img_mask\n",
    "\n",
    "\n",
    "\n",
    "damage_dict = {\n",
    "    \"no-damage\": 1,\n",
    "    \"minor-damage\": 2,\n",
    "    \"major-damage\": 3,\n",
    "    \"destroyed\": 4,\n",
    "    \"un-classified\": 1,\n",
    "    \"No visible damage\": 1,\n",
    "    \"Possibly damaged\": 2,\n",
    "    \"Damaged\":3,\n",
    "    \"Destroyed\":4\n",
    "}\n",
    "\n",
    "\n",
    "def process_image(json_file):\n",
    "    js1 = json.load(open(json_file))\n",
    "    js2 = json.load(open(json_file.replace('_pre_disaster', '_post_disaster')))\n",
    "\n",
    "    msk = np.zeros((1024, 1024), dtype='uint8')\n",
    "    msk_damage = np.zeros((1024, 1024), dtype='uint8')\n",
    "\n",
    "    for feat in js1['features']['xy']:\n",
    "        poly = loads(feat['wkt'])\n",
    "        _msk = mask_for_polygon(poly)\n",
    "        msk[_msk > 0] = 255\n",
    "\n",
    "    for feat in js2['features']['xy']:\n",
    "        poly = loads(feat['wkt'])\n",
    "        subtype = feat['properties']['subtype']\n",
    "        _msk = mask_for_polygon(poly)\n",
    "        msk_damage[_msk > 0] = damage_dict[subtype]\n",
    "\n",
    "    cv2.imwrite(json_file.replace('_wkt_', '_mask_').replace('.json', '.png'), msk, [cv2.IMWRITE_PNG_COMPRESSION, 9])\n",
    "    cv2.imwrite(json_file.replace('_wkt_', '_mask_').replace('_pre_disaster', '_post_disaster').replace('.json', '.png'), msk_damage, [cv2.IMWRITE_PNG_COMPRESSION, 9])\n",
    "    \n",
    "    \n",
    "def process_image_updated(json_file):\n",
    "    msk = np.zeros((1024, 1024), dtype='uint8')\n",
    "    msk_damage = np.zeros((1024, 1024), dtype='uint8')\n",
    "\n",
    "    if('pre_disaster' in json_file):\n",
    "        js1 = json.load(open(json_file))\n",
    "\n",
    "        for feat in js1['features']['xy']:\n",
    "            poly = loads(feat['wkt'])\n",
    "            _msk = mask_for_polygon(poly)\n",
    "            msk[_msk > 0] = 255\n",
    "\n",
    "        cv2.imwrite(json_file.replace('_wkt_', '_mask_').replace('.json', '.png'), msk, [cv2.IMWRITE_PNG_COMPRESSION, 9])\n",
    "\n",
    "    if('post_disaster' in json_file):\n",
    "        js2 = json.load(open(json_file))\n",
    "        for feat in js2['features']['xy']:\n",
    "            poly = loads(feat['wkt'])\n",
    "            subtype = feat['properties']['subtype']\n",
    "            _msk = mask_for_polygon(poly)\n",
    "            msk_damage[_msk > 0] = damage_dict[subtype]\n",
    "        cv2.imwrite(json_file.replace('_wkt_', '_mask_').replace('.json', '.png'), msk_damage, [cv2.IMWRITE_PNG_COMPRESSION, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "99465f00-7cd1-4b80-b8f7-bf7aeb73830f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['turkey_earthquake/labels/copernicus_earthquake_turkey_tile_wkt_02-23/Osmaniye/Osmaniye_20221227_10300100DF069700_pre_disaster_2_15.json',\n",
       " 'turkey_earthquake/labels/copernicus_earthquake_turkey_tile_wkt_02-23/Osmaniye/Osmaniye_20230208_10300500D9F8D400_post_disaster_2_0.json',\n",
       " 'turkey_earthquake/labels/copernicus_earthquake_turkey_tile_wkt_02-23/Osmaniye/Osmaniye_20221227_10300100DF069700_pre_disaster_7_9.json',\n",
       " 'turkey_earthquake/labels/copernicus_earthquake_turkey_tile_wkt_02-23/Osmaniye/Osmaniye_20221227_10300100DF069700_pre_disaster_5_11.json',\n",
       " 'turkey_earthquake/labels/copernicus_earthquake_turkey_tile_wkt_02-23/Osmaniye/Osmaniye_20221227_10300100DF069700_pre_disaster_12_4.json']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def list_json_files_recursive(directory):\n",
    "    json_file_list = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                json_file_list.append(os.path.join(root, file))\n",
    "    return json_file_list\n",
    "\n",
    "def list_subdirectories(directory_path):\n",
    "    subdirectories = [d for d in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, d))]\n",
    "    return subdirectories\n",
    "\n",
    "\n",
    "label_dirs = 'turkey_earthquake/labels/copernicus_earthquake_turkey_tile_wkt_02-23/'\n",
    "list_json_files_recursive(label_dirs)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "84f89d23-bd36-48dd-8fc5-beb768e9a8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d81c96a1f5b64ec9b08879c7edd71dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/443 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.9 s, sys: 119 ms, total: 20 s\n",
      "Wall time: 20.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm.notebook import tqdm\n",
    "## RUN\n",
    "masks_dir = 'turkey_earthquake/labels/copernicus_earthquake_turkey_tile_mask_02-23'\n",
    "label_dirs = 'turkey_earthquake/labels/copernicus_earthquake_turkey_tile_wkt_02-23'\n",
    "label_files = list_json_files_recursive(label_dirs)\n",
    "\n",
    "#ensure there is a directory\n",
    "makedirs(masks_dir, exist_ok=True)\n",
    "city_list = list_subdirectories(label_dirs)\n",
    "# city dir\n",
    "for city in city_list:\n",
    "    # Ensure the directories exist\n",
    "    Path(masks_dir+city+'/').mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "#ensure there is a directory\n",
    "makedirs(masks_dir, exist_ok=True)\n",
    "for file_path in tqdm(sorted(label_files)):\n",
    "    process_image_updated(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373f9685-4472-43f8-b9ec-e9cc63d2e7cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
